CS 514 HW9 solutions

1. Dijkstra:

   Q: What if you only have heapq, can you still make Dijkstra work (with the built-in heapq)?
      Can you re-analyze the time/space complexities?

   A: If our priority queue assumes static priorities (i.e., no decrease-key operation), then there might be duplicate entries of each node (with different values) in the priority queue, and each node might be popped from the queue multiple times. Note that only the first pop of each node contains the optimal value for that node, and you can ignore all future pops of that node (it's already black).

   new complexity: O(ElogE + ElogE) = O(ElogE).
   this is because in the worse case there are E possible updates (one for each edge), each of which can be stored in the queue (without a mechanism of checking duplicates or updating the key), so the size of the queue is also O(E). Therefore in the worst case there will be E possible pops (though only V of them are useful). Thus E pops and E pushes, each with O(logE).

   compare with standard Dijkstra: O(VlogV + ElogV) = O((V+E)logV).

   note that the difference between the two complexities is really minor. Even for a dense graph, i.e., E=O(V^2), the difference is only in the constant factor, since O(ElogE) = O(2 V^2 logV) and O((V+E)logV) = O(V^2 logV).

   in reality, sometimes the heapq version could even be faster, since maintaining an indexed priority queue is non-trivial (with a large constant factor).


   Q: Is Dijkstra a greedy algorithm or dynamic programming algorithm?
      Most textbooks (such as KT and CLRS) classify it as a greedy algorithm,
      but some people have different opinions, e.g.:
      https://www.quora.com/Is-Dijkstras-Algorithm-a-greedy-algorithm-or-a-dynamic-programming-a
lgorithm
      https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm#Dynamic_programming_perspective

      What do you think?

   A: Dijkstra is certainly a DP algorithm and not a greedy one. Famous textbooks like CLRS and KT are totally wrong about this, while references [1-3] are correct.

      A greedy algorithm makes a decision which can not be revised in the future, while a DP algorithm is global optimization and the final decision must be backtraced from the target node. During Dijkstra, each node keeps being updated (until popped), and there is no way of telling whether a node is included in the global best solution from source to target until the very end, which is very different from a greedy algorithm which keeps expanding one single solution (i.e., a path from source). Dijkstra is just a different style of DP, which visits subproblems in a best-first rather than topological order. If you don't think Dijkstra is DP, then you're restricting DP to only Viterbi-style.

      See more details in:
      [1] L. Huang, Advanced Dynamic Programming in Semiring and Hypergraph Frameworks (2008). 
      https://aclanthology.org/C08-5001.pdf
      [2] M. Sniedovich, Dijkstra's algorithm revisited: the dynamic programming connexion (2006). 
      http://matwbn.icm.edu.pl/ksiazki/cc/cc35/cc3536.pdf
      [3] Wikipedia: 
      https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm#Dynamic_programming_perspective

      Note: that being said, a closely related algorithm, Prim's algorithm for minimum spanning tree, which looks almost identical to Dijkstra's, is indeed greedy, because it always expands one single solution (a partial spanning tree).

   Q: for problems that can be solved by both Dijkstra and Viterbi, which one is faster?

   A: (assuming single source, single destination) depends on the graph. The key insight is that Dijkstra can skip a lot of "useless nodes", if they are even worse than the target in terms of distance (thus never useful in updating the target); but Viterbi also skips nodes that are *after* the target node in the topological order for similar reasons. So it really depends on how early the target node gets blackend in each algorithm. Let's say in Viterbi, the target node ranks x (out of n) in the topological order, and in Dijkstra, it ranks y (out of n) by value (distance), then it depends on the comparison between x/y and logV.

   For the case of single-source, all destinations: then Viterbi is always faster, as both algorithms have to visit all nodes.

2. TSP:

   space: O(2^n n); time: O(2^n n^2). <-- classical Bellman-Held-Karp algorithm.

   caveat: but actually, because hashing a frozenset or high-precision integer also takes O(n) time, in reality:
   space: O(2^n n^2); time: O(2^n n^3).   

$ python3 tsp.py

Viterbi, bit, time: 0.00 pushes: 10 pops: 10
(14, [0, 1, 3, 2, 0])
Viterbi, bit, time: 0.00 pushes: 15 pops: 13
(5, [0, 1, 2, 3, 0])

Germany graph...
Viterbi, bit, time: 0.02 pushes: 11384 pops: 5121
(253, [0, 7, 4, 3, 9, 5, 2, 6, 1, 10, 8, 0])
Dijkstra, bit, decrease-key, time: 0.03 pushes: 9074 pops: 5122
(253, [0, 8, 10, 1, 6, 2, 5, 9, 3, 4, 7, 0])
Dijkstra, bit, heapq, time: 0.02 pushes: 9074 pops: 8811
(253, [0, 8, 10, 1, 6, 2, 5, 9, 3, 4, 7, 0])

Random graph 1... (Viterbi faster)
Viterbi, set, time: 1.99 pushes: 645399 pops: 245761
(238, [0, 11, 1, 9, 2, 13, 5, 6, 3, 10, 4, 7, 8, 12, 15, 14, 0])
Viterbi, bit, time: 1.15 pushes: 645399 pops: 245761
(238, [0, 11, 1, 9, 2, 13, 5, 6, 3, 10, 4, 7, 8, 12, 15, 14, 0])
Dijkstra, bit, decrease-key, time: 2.26 pushes: 473328 pops: 244846
(238, [0, 14, 15, 12, 8, 7, 4, 10, 3, 6, 5, 13, 2, 9, 1, 11, 0])
Dijkstra, bit, heapq, time: 2.63 pushes: 473328 pops: 444940
(238, [0, 14, 15, 12, 8, 7, 4, 10, 3, 6, 5, 13, 2, 9, 1, 11, 0])

Random graph 2... (Dijkstra faster)
Viterbi, set, time: 1.20 pushes: 343830 pops: 207691
(6, [0, 2, 6, 15, 11, 9, 12, 13, 3, 10, 5, 7, 1, 4, 8, 14, 0])
Viterbi, bit, time: 0.64 pushes: 343830 pops: 207691
(6, [0, 2, 6, 15, 11, 9, 12, 13, 3, 10, 5, 7, 1, 4, 8, 14, 0])
Dijkstra, bit, decrease-key, time: 0.13 pushes: 48783 pops: 19749
(6, [0, 4, 8, 14, 7, 5, 10, 3, 13, 12, 9, 11, 15, 6, 2, 1, 0])
Dijkstra, bit, heapq, time: 0.11 pushes: 48783 pops: 20599
(6, [0, 4, 8, 14, 7, 5, 10, 3, 13, 12, 9, 11, 15, 6, 2, 1, 0])

PLEASE READ AND TRY OUR CODE.